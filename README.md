# FrequentItemsetAnalysisonAmazonMetadata_A3

##Overview
This project implements a streaming pipeline to process product data from the Amazon metadata dataset. The pipeline includes preprocessing of the data, a producer application to stream the preprocessed data in real-time, three consumer applications for frequent itemset mining using Apriori and PCY algorithms, and a recommendation system based on consumer preferences. MongoDB is utilized to store the results of each consumer's output.

## 1-Sampling
A sampling approach is implemented to handle a larger dataset of 15 GB. This enables efficient processing of a subset of the dataset for testing and experimentation purposes.

## 2-Preprocessing
The dataset is preprocessed to extract relevant fields such as ASIN, title, features, description, price, brand, categories, etc. We generated a JSON file.

## 3-Producer
The producer application reads the preprocessed data and streams it in real-time. It publishes the data to a messaging system using Apache Kafka for consumption by the consumer applications.

## 4-Consumer
##Consumer 1 - Apriori Algorithm
Consumer 1 implements the Apriori algorithm for frequent itemset mining. It processes the incoming data stream and identifies frequent itemsets and association rules in real-time. The results are printed to the console, providing insights into product associations.

##Consumer 2 - PCY Algorithm
Consumer 2 implements the PCY (Park-Chen-Yu) algorithm for frequent itemset mining. Similar to Consumer 1, it processes the streaming data and identifies frequent itemsets and association rules using the PCY algorithm. Real-time insights and associations are printed to the console.

##Consumer 3 - Recommendation System
Consumer 3 is dedicated to building a recommendation system based on consumer preferences. It analyzes the streaming data to understand consumer behavior and preferences. Recommendations are generated dynamically, considering factors such as product popularity, consumer interactions, and price adjustments. Additionally, bundled product suggestions are provided to enhance the shopping experience.

## 5-MongoDB Integration
Each consumer application is modified to connect to a MongoDB database for storing the results of its output. MongoDB collections are created to represent the data structure of the consumer outputs. The integration enables efficient storage and retrieval of insights and recommendations generated by the consumer applications.

## 6-Dependencies
Python 3.x
MongoDB
Kafka or RabbitMQ (for messaging)
Required Python libraries (e.g., pymongo, kafka-python, etc.)

## 7-Contributors
Hasnat Noor Hassan  |I22-2049|
Hamza Zahid |I22-1974|
Umaima Azhar |I22-2036|

## 8-License
This project is licensed under the "HASNAT GROUP OF COMPANIES" License - see the LICENSE file for details.
